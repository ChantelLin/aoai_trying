{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27fcf8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try langchain pdf loader + vector db\n",
    "# https://medium.com/@cch.chichieh/rag%E5%AF%A6%E4%BD%9C%E6%95%99%E5%AD%B8-langchain-llama2-%E5%89%B5%E9%80%A0%E4%BD%A0%E7%9A%84%E5%80%8B%E4%BA%BAllm-d6838febf8c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt\n",
    "#pip install langchain-openai for using azureopenai\n",
    "# %pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41ec55a-6356-4a58-a9de-506cec478e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "# get config from aoai_config.yaml\n",
    "\n",
    "%run env_config_setting.ipynb\n",
    "\n",
    "api_version = openai.api_version\n",
    "api_key = openai.api_key\n",
    "api_base = openai.api_base\n",
    "\n",
    "print('openi config: ', deployment_name, embedding_name, api_key, api_base, api_version)\n",
    "print('search config: ', search_service_name, search_key, search_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13be9c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './pdfs/eda_llm_future.pdf', 'page': 0}, page_content='Large Language Models for EDA: Future or Mirage?\\nZhuolun He\\nThe Chinese University of Hong Kong\\nHong Kong SARBei Yu\\nThe Chinese University of Hong Kong\\nHong Kong SAR\\nABSTRACT\\nIn this paper, we explore the burgeoning intersection of Large Lan-\\nguage Models (LLMs) and Electronic Design Automation (EDA). We\\ncritically assess whether LLMs represent a transformative future\\nfor EDA or merely a fleeting mirage. By analyzing current advance-\\nments, challenges, and potential applications, we dissect how LLMs\\ncan revolutionize EDA processes like design, verification, and op-\\ntimization. Furthermore, we contemplate the ethical implications\\nand feasibility of integrating these models into EDA workflows. Ulti-\\nmately, this paper aims to provide a comprehensive, evidence-based\\nperspective on the role of LLMs in shaping the future of EDA.\\nACM Reference Format:\\nZhuolun He and Bei Yu. 2024. Large Language Models for EDA: Future or\\nMirage? . In Proceedings of the 2024 International Symposium on Physical\\nDesign (ISPD ’24), March 12–15, 2024, Taipei, Taiwan. ACM, New York, NY,\\nUSA, 2pages. https://doi.org/10.1145/3626184.3639700\\n1 INTRODUCTION\\nThe advent of Large Language Models (LLMs) has ushered in a\\nnew era in the realm of artificial intelligence, redefining the bound-\\naries of machine learning and its applications. One such field that\\nstands on the cusp of potential transformation is Electronic De-\\nsign Automation (EDA). EDA, a cornerstone in the semiconductor\\nindustry, encompasses a suite of software tools for designing elec-\\ntronic systems such as integrated circuits and printed circuit boards.\\nThe integration of LLMs into EDA promises to revolutionize this\\nfield, offering unprecedented capabilities in design automation, error\\ndetection, and process optimization.\\nThis paper seeks to explore the intersection of LLMs with EDA,\\ncritically examining whether this integration heralds a new future\\nor is merely an overhyped concept. The surge in LLM capabilities,\\ncharacterized by models such as GPT-4, has demonstrated profound\\npotential in understanding and generating human-like text. This\\ncapability, when applied to EDA, could offer transformative solutions\\nin automating complex design processes, providing natural language\\ninterfaces for design tools, and enhancing the accuracy of predictive\\nmodels used in circuit design and analysis.\\nHowever, the marriage of LLMs with EDA is not without its chal-\\nlenges. The complexity of EDA tasks, coupled with the specialized\\nnature of electronic design languages, poses a significant hurdle.\\nMoreover, the integration of LLMs raises pertinent ethical and prac-\\ntical concerns. Issues such as data privacy, model reliability, and the\\nPermission to make digital or hard copies of part or all of this work for personal or\\nclassroom use is granted without fee provided that copies are not made or distributed\\nfor profit or commercial advantage and that copies bear this notice and the full citation\\non the first page. Copyrights for third-party components of this work must be honored.\\nFor all other uses, contact the owner/author(s).\\nISPD ’24, March 12–15, 2024, Taipei, Taiwan\\n©2024 Copyright held by the owner/author(s).\\nACM ISBN 979-8-4007-0417-8/24/03.\\nhttps://doi.org/10.1145/3626184.3639700potential for automation-induced obsolescence in skilled professions\\nare critical considerations that must be addressed.\\nIn this paper, we delve into the nuances of applying LLMs to EDA.\\nWe analyze current trends, potential applications, and the challenges\\nfaced in actualizing this integration. By examining case studies and\\nemerging research, we aim to provide a comprehensive overview of\\nhow LLMs could potentially reshape the future of EDA, evaluating\\nwhether this integration is a groundbreaking advancement or an\\noverestimated prospect.\\n2 APPLICATIONS FOR EDA\\nThere are many applications applying LLM into circuit design and\\nthe EDA flow. For example, ChipNeMo [ 1] aims to optimize the\\nutilization of LLMs in chip design by employing domain adaptation\\ntechniques instead of relying solely on off-the-shelf LLMs. These\\ntechniques include custom tokenizers, domain-adaptive continued\\npretraining, supervised fine-tuning with domain-specific instruc-\\ntions, and domain-adapted retrieval models. The effectiveness of\\nthese techniques is evaluated through three selected LLM applica-\\ntions: an engineering assistant chatbot, EDA script generation, and\\nbug summarization and analysis. By training on 128 A100 GPUs,\\nChipNeMo has demonstrated impressive results in the selected ap-\\nplications. However, the evaluation results indicate a considerable\\ndisparity compared to human expert performance. To bridge this\\nperformance gap, several approaches are being considered by the au-\\nthors, including data collection with more internal proprietary data,\\nintegrating better code-based base model, conducting reinforcement\\nlearning from human feedback (RLHF) [ 2], and investigating better\\nRAG methods.\\nThe most popular application is to help circuit design with LLM:\\nprior works [ 3–7], among many others, are all very recent attempts\\ntowards this direction. VerilogEval [ 5] introduces a benchmarking\\nframework specifically designed to evaluate the performance of\\nLLMs in generating Verilog code for hardware design and verifica-\\ntion. The evaluation dataset covers a wide range of Verilog code\\ngeneration tasks, varying from simple combinational circuits to com-\\nplex finite state machines. To assess the functional correctness of the\\ngenerated Verilog code, transient simulation outputs are compared\\nwith a golden solution, enabling automated testing. Similarly, Thakur\\net al. [ 3] fine-tune pre-trained LLMs using Verilog datasets sourced\\nfrom GitHub and Verilog textbooks. They develop an evaluation\\nframework that includes test-benches for functional analysis and a\\nflow to test the syntax of the generated Verilog code across various\\nproblem scenarios. GPT4AIGChip [ 6] is a framework that leverages\\nLLMs and human natural languages to democratize AI accelera-\\ntor design. The framework features an automated demo-augmented\\nprompt-generation pipeline that utilizes in-context learning to guide\\nLLMs in generating high-quality AI accelerator designs. The authors\\nhighlight the insights and guidelines derived from understanding the\\nlimitations and exploitable capabilities of LLMs for AI accelerator\\n65\\n'),\n",
       " Document(metadata={'source': './pdfs/eda_llm_future.pdf', 'page': 1}, page_content='design automation, such as decoupled hardware template design, pri-\\noritizing in-context learning given limited data, and proper prompt\\nengineering. ChipChat [ 4] authors argue that when human feed-\\nback is incorporated into the more advanced ChatGPT-4 model or\\nused for co-design, the language model acts as a ’force multiplier’,\\nenabling quick exploration and iteration of the design space.\\nThe second interesting direction is to help the design flow with\\nLLM. ChatEDA [ 8] addresses the challenge of integrating EDA tools\\nto improve interoperability in circuit design, by leveraging LLM\\ncapabilities in natural language processing and comprehension. An\\nautonomous agent for EDA that utilizes the AutoMage LLM in con-\\njunction with EDA tools as executors is proposed. It offers users\\na conversational interface to interact with these tools. Users can\\ncommunicate their requirements using natural language prompts,\\nand ChatEDA’s goal is to generate executable programs (scripts) that\\nfulfill the user’s specific needs. Acting as the controller, ChatEDA\\norchestrates the collaboration between these tools. It starts by cre-\\nating a task list based on user requirements and then generates\\nscripts for each task. The conversational interaction may inspire\\nnext-generation EDA tool evolution.\\nThe third direction is debugging in Verilog: RTLFixer [ 9] is an au-\\ntomated framework that addresses syntax-related errors in Verilog\\ncode using LLMs. It consists of an LLM for code generation, RAG for\\naccessing expert guidance, and ReAct for task decomposition and\\nplanning. The framework starts by formulating an input prompt\\ncombining a benchmark problem with a template. RAG and ReAct\\nare then used to revise the code and resolve errors. Persistent syntax\\nerrors are addressed with feedback from compiler error logs and\\nretrieved human guidance. This iterative debugging process contin-\\nues until all errors are resolved. RTLFixer achieves a high success\\nrate of 98 .5%in fixing compilation errors and significantly improves\\npass rates in VerilogEval benchmarks. Specifically, it enhances the\\npass@1 success rates by 32 .3%in VerilogEval-Machine and 10 .1%in\\nVerilogEval-Human benchmarks.\\n3 CONCLUSION AND FUTURE DIRECTIONS\\nThis paper has embarked on a comprehensive exploration of the\\nintegration of LLMs into EDA. Our analysis reveals a landscape\\nbrimming with potential, yet punctuated by significant challenges\\nand uncertainties. The promise of LLMs in enhancing EDA processes\\nis undeniable, offering novel approaches to design automation, error\\ndetection, and efficiency improvements. However, the path to fully\\nrealizing this potential is fraught with technical, ethical, and practical\\nobstacles.\\nThe future of LLMs in EDA hinges on several key factors. Firstly,\\nthe development of more specialized LLMs tailored to understand\\nthe intricacies of electronic design languages and processes is crucial.\\nThe current generation of LLMs, while advanced, is predominantly\\ntrained on general language data. For LLMs to be truly transforma-\\ntive in EDA, they must evolve to comprehend the specialized syntax\\nand semantics of electronic design, a process that requires exten-\\nsive domain-specific data and training. Data generation techniques\\nlike self-instruct [ 10] are of great significance. Careful selection or\\ncombination between RAG and fine-tuning [ 11] is also crucial in\\nachieving optimal results.Secondly, addressing ethical and practical concerns is paramount.\\nIssues such as data security, privacy, and the ethical use of AI in\\nprofessional settings need rigorous standards and regulatory frame-\\nworks. Recent studies have demonstrate the vulnerabilities of LLMs\\nwhen faced with malicious user interactions, and prompt injection\\ntechniques are proposed [ 12]. As LLMs become more integrated into\\nEDA, it is vital to ensure that these tools are used responsibly, with\\na clear understanding of their limitations and potential biases.\\nLooking ahead, the future directions of LLM integration into\\nEDA are manifold. One promising avenue is the development of\\nAI-assisted design tools that seamlessly integrate with existing EDA\\nsoftware, offering enhanced capabilities in design optimization and\\nerror correction. Another area of exploration is the use of LLMs\\nin educational settings, where they can aid in training the next\\ngeneration of electronic designers, providing interactive learning\\nexperiences and personalized feedback.\\nFurthermore, there is substantial scope for collaborative research\\nbetween AI experts and EDA professionals. Such collaboration can\\naccelerate the development of customized LLMs that cater specifi-\\ncally to the needs of the EDA industry. Additionally, exploring the\\npotential of LLMs in related fields like chip layout optimization\\nand predictive maintenance of electronic systems could open new\\nfrontiers in the application of AI in electronics.\\nIn conclusion, while the integration of LLMs into EDA presents a\\nlandscape rich with opportunities, it remains a complex and evolv-\\ning field. Continued research, interdisciplinary collaboration, and\\nmindful consideration of ethical implications are essential in steer-\\ning this integration towards a future that is not only technologically\\nadvanced but also responsible and inclusive. As we stand at the\\ncusp of this technological evolution, it is imperative to navigate this\\njourney with a balanced perspective, embracing innovation while\\nremaining cognizant of the challenges that lie ahead.\\nREFERENCES\\n[1]M. Liu, T.-D. Ene, R. Kirby, C. Cheng, N. Pinckney, R. Liang, J. Alben, H. Anand,\\nS. Banerjee, I. Bayraktaroglu et al., “ChipNeMo: Domain-Adapted LLMs for Chip\\nDesign, ” arXiv preprint arXiv:2311.00176, 2023.\\n[2]L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang,\\nS. Agarwal, K. Slama, A. Ray et al., “Training language models to follow instructions\\nwith human feedback, ” Proc. NeurIPS, vol. 35, pp. 27 730–27 744, 2022.\\n[3]S. Thakur, B. Ahmad, Z. Fan, H. Pearce, B. Tan, R. Karri, B. Dolan-Gavitt, and\\nS. Garg, “Benchmarking Large Language Models for Automated Verilog RTL Code\\nGeneration, ” in Proc. DATE, 2023, pp. 1–6.\\n[4]J. Blocklove, S. Garg, R. Karri, and H. Pearce, “Chip-Chat: Challenges and Oppor-\\ntunities in Conversational Hardware Design, ” in Proc. MLCAD, 2023.\\n[5]M. Liu, N. Pinckney, B. Khailany, and H. Ren, “VerilogEval: Evaluating Large\\nLanguage Models for Verilog Code Generation, ” in Proc. ICCAD, 2023.\\n[6]Y. Fu, Y. Zhang, Z. Yu, S. Li, Z. Ye, C. Li, C. Wan, and Y. C. Lin, “GPT4AIGChip:\\nTowards next-generation AI accelerator design automation via large language\\nmodels, ” in Proc. ICCAD, 2023.\\n[7]K. Chang, Y. Wang, H. Ren, M. Wang, S. Liang, Y. Han, H. Li, and X. Li,\\n“ChipGPT: How far are we from natural language hardware design, ” arXiv preprint\\narXiv:2305.14019, 2023.\\n[8]Z. He, H. Wu, X. Zhang, X. Yao, S. Zheng, H. Zheng, and B. Yu, “ChatEDA: A Large\\nLanguage Model Powered Autonomous Agent for EDA, ” in Proc. MLCAD, 2023.\\n[9]Y. Tsai, M. Liu, and H. Ren, “RTLFixer: Automatically Fixing RTL Syntax Errors\\nwith Large Language Models, ” arXiv preprint arXiv:2311.16543, 2023.\\n[10] Y. Wang, Y. Kordi, S. Mishra, A. Liu, N. A. Smith, D. Khashabi, and H. Hajishirzi,\\n“Self-instruct: Aligning language model with self generated instructions, ” arXiv\\npreprint arXiv:2212.10560, 2022.\\n[11] Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, and H. Wang,\\n“Retrieval-augmented generation for large language models: A survey, ” arXiv\\npreprint arXiv:2312.10997, 2023.\\n[12] F. Perez and I. Ribeiro, “Ignore previous prompt: Attack techniques for language\\nmodels, ” arXiv preprint arXiv:2211.09527, 2022.\\nISPD ’24, March 12–15, 2024, Taipei, Taiwan\\nZhuolun He & Bei Yu\\n66')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./pdfs/eda_llm_future.pdf\")\n",
    "PDF_data = loader.load()\n",
    "\n",
    "#PyMuPDFLoader without table and image elements \n",
    "#圖片文字跟table 欄位 內容都有x擷取出來 但是沒有圖片資訊\n",
    "# has \\n for each line\n",
    "PDF_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b799763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# chunk_overlap 設5 但是看起來沒有重疊的部分 ?\n",
    "# chunk_size 設100 但針對每個切完的文字放到word 透過「字數統計」。也有長度是超過字元數100的 ?\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=5)\n",
    "all_splits = text_splitter.split_documents(PDF_data)\n",
    "#all_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19741d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embedding = AzureOpenAIEmbeddings(\n",
    "    deployment=embedding_name,\n",
    "    azure_endpoint=api_base,\n",
    "    api_key=api_key,\n",
    "    chunk_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bfe3a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⚠️ It looks like you upgraded from a version below 0.6 and could benefit from vacuuming your database. Run chromadb utils vacuum --help for more information.\n",
      "/var/folders/n7/1tk7cfpx0_31x9yrrl6skynh0000gn/T/ipykernel_15034/3739428637.py:11: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "#if using different embedding model, need saved other db file\n",
    "\n",
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "#this will create a folder [db] and add a new file chroma.sqlite3\n",
    "\n",
    "persist_directory = 'chroma_langchain_aoai_retrieval_try'\n",
    "vectordb = Chroma.from_documents(documents=all_splits, embedding=embedding, persist_directory=persist_directory)\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "318a3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents_by_chroma(index=persist_directory, query=\"\", limit=5):\n",
    "    vectordb = Chroma(persist_directory=index, embedding_function=embedding)\n",
    "    docs = vectordb.similarity_search(query, k=limit)\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70a04d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n7/1tk7cfpx0_31x9yrrl6skynh0000gn/T/ipykernel_15034/1162148580.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(persist_directory=index, embedding_function=embedding)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'author': '', 'creationDate': \"D:20240108184338+00'00\", 'creator': 'LaTeX with hyperref package', 'file_path': '/Users/lizylin/Downloads/[2023] LADAC Large Language Model-driven Auto-Designer for Analog Circuits.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': \"D:20240108184338+00'00\", 'page': 5, 'producer': 'Ruby CombinePDF 1.0.21 Library', 'source': '/Users/lizylin/Downloads/[2023] LADAC Large Language Model-driven Auto-Designer for Analog Circuits.pdf', 'subject': '', 'title': '', 'total_pages': 10, 'trapped': ''}, page_content='ually refined knowledge about multi-stage amplifiers, ring'),\n",
       " Document(metadata={'author': '', 'creationDate': \"D:20240108184338+00'00\", 'creator': 'LaTeX with hyperref package', 'file_path': '/Users/lizylin/Downloads/[2023] LADAC Large Language Model-driven Auto-Designer for Analog Circuits.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': \"D:20240108184338+00'00\", 'page': 6, 'producer': 'Ruby CombinePDF 1.0.21 Library', 'source': '/Users/lizylin/Downloads/[2023] LADAC Large Language Model-driven Auto-Designer for Analog Circuits.pdf', 'subject': '', 'title': '', 'total_pages': 10, 'trapped': ''}, page_content='local knowledge library, including the multi-stage amplifier'),\n",
       " Document(metadata={'author': '', 'creationDate': \"D:20240108184338+00'00\", 'creator': 'LaTeX with hyperref package', 'file_path': '/Users/lizylin/Downloads/[2023] LADAC Large Language Model-driven Auto-Designer for Analog Circuits.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': \"D:20240108184338+00'00\", 'page': 5, 'producer': 'Ruby CombinePDF 1.0.21 Library', 'source': '/Users/lizylin/Downloads/[2023] LADAC Large Language Model-driven Auto-Designer for Analog Circuits.pdf', 'subject': '', 'title': '', 'total_pages': 10, 'trapped': ''}, page_content='as a callable function. Furthermore, the multistage amplifier'),\n",
       " Document(metadata={'author': '', 'creationDate': \"D:20240108184338+00'00\", 'creator': 'LaTeX with hyperref package', 'file_path': '/Users/lizylin/Downloads/[2023] LADAC Large Language Model-driven Auto-Designer for Analog Circuits.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': \"D:20240108184338+00'00\", 'page': 5, 'producer': 'Ruby CombinePDF 1.0.21 Library', 'source': '/Users/lizylin/Downloads/[2023] LADAC Large Language Model-driven Auto-Designer for Analog Circuits.pdf', 'subject': '', 'title': '', 'total_pages': 10, 'trapped': ''}, page_content='Multi-stage amplifier part leverages the existing knowledge'),\n",
       " Document(metadata={'author': '', 'creationDate': \"D:20240108184338+00'00\", 'creator': 'LaTeX with hyperref package', 'file_path': '/Users/lizylin/Downloads/[2023] LADAC Large Language Model-driven Auto-Designer for Analog Circuits.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': \"D:20240108184338+00'00\", 'page': 6, 'producer': 'Ruby CombinePDF 1.0.21 Library', 'source': '/Users/lizylin/Downloads/[2023] LADAC Large Language Model-driven Auto-Designer for Analog Circuits.pdf', 'subject': '', 'title': '', 'total_pages': 10, 'trapped': ''}, page_content='based on the tools, local knowledge library, and the prompt\\nwe provide.\\nA. Two-stage amplifier')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_documents_by_chroma(query=\"what is multi-stage amplifiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6597464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "client = AzureChatOpenAI(\n",
    "    deployment_name=deployment_name,\n",
    "    temperature=0,\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=api_base,\n",
    "    openai_api_version=api_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd7504d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=client, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "300a3924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'what is LADAC?',\n",
       " 'result': 'LADAC is a new circuit design process that utilizes the LLM (Large Language Model) agent approach. It is guided by a local knowledge library and aims to demonstrate practicality and potential in circuit design.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke(\"what is LADAC?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c708ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n7/1tk7cfpx0_31x9yrrl6skynh0000gn/T/ipykernel_15034/2444668796.py:4: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa({\"query\": q1, \"chat_history\": chat_history})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'what part is the most important',\n",
       " 'chat_history': [],\n",
       " 'result': \"I don't have enough context to determine which part is the most important. The provided text seems to be fragmented and lacks specific details about the subject matter. If you can provide more context or clarify your question, I might be able to help better.\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "q1 = \"what part is the most important\"\n",
    "result = qa({\"query\": q1, \"chat_history\": chat_history})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3e6dc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'what part is the most important in LADAC?',\n",
       " 'chat_history': [('what part is the most important',\n",
       "   \"I don't have enough context to determine which part is the most important. The provided text seems to be fragmented and lacks specific details about the subject matter. If you can provide more context or clarify your question, I might be able to help better.\")],\n",
       " 'result': 'The central component of LADAC is considered the most important part.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append((q1, result['result']))\n",
    "\n",
    "q1 = \"what part is the most important in LADAC?\"\n",
    "result = qa({\"query\": q1, \"chat_history\": chat_history})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====== use promptTemplate and ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa6a33ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Adapt if needed\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(\"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\")\n",
    "\n",
    "crqa = ConversationalRetrievalChain.from_llm(llm=client,\n",
    "                                           retriever=retriever,\n",
    "                                           condense_question_prompt=CONDENSE_QUESTION_PROMPT,\n",
    "                                           return_source_documents=True,\n",
    "                                           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd61d3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "V. CONCLUSION\n",
      "In this study, we have presented LADAC, which is a new\n",
      "\n",
      "circuit design process by using the LLM agent approach.\n",
      "III. OVERVIEW OF LADAC\n",
      "\n",
      "Guided by the local knowledge library, LADAC achieves\n",
      "TABLE I\n",
      "\n",
      "• Demonstrating the practicality and potential of LADAC\n",
      "Human: what is LADAC?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "LADAC is a new circuit design process that utilizes the LLM (Large Language Model) agent approach.\n"
     ]
    }
   ],
   "source": [
    "crchat_history = []\n",
    "query = \"what is LADAC?\"\n",
    "crresult = crqa({\"question\": query, \"chat_history\": crchat_history})\n",
    "print(crresult[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
